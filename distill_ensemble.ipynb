{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37500, 32, 32, 3) (37500, 10) (12500, 32, 32, 3) (12500, 10) (10000, 32, 32, 3) (10000, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.] cat\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10 \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(train_images, train_labels), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "train_images = train_images.astype('float32')/255.0\n",
    "x_test = x_test.astype('float32')/255.0\n",
    "train_labels = to_categorical(train_labels, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_images,train_labels,random_state=123)\n",
    "\n",
    "print(x_train.shape,\n",
    "      y_train.shape,\n",
    "      x_val.shape,\n",
    "      y_val.shape,\n",
    "      x_test.shape,\n",
    "      y_test.shape)\n",
    "\n",
    "def labeling_vec(t):\n",
    "    label_list = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "    ll = np.arange(10)\n",
    "    l = np.dot(t,ll)\n",
    "    return label_list[int(l)]\n",
    "\n",
    "k = 9\n",
    "plt.imshow(x_train[k])\n",
    "plt.show()\n",
    "print(y_train[k],labeling_vec(y_train[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "# 使うGPU番号を指定(私の場合は9番を使用)\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "\n",
    "# tensorflowは普通に使用すると、GPUメモリを取れるだけとってしまうため、最小限だけ使うように設定する。（命苫メソッド）\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "EPOCHS = 150\n",
    "# 学習率\n",
    "def step_decay(epoch):\n",
    "    x = 0.0001\n",
    "    warmup = 5\n",
    "    if epoch < warmup:\n",
    "        x *= (epoch+1)/warmup\n",
    "    else:\n",
    "        x *= (1 + np.cos(np.pi*(epoch+1-warmup)/EPOCHS))/2\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def basic_conv_block(input, chs, sh, reps): ##sh畳み込み大きさ, reps回数\n",
    "    x = input\n",
    "    for i in range(reps):\n",
    "        x = layers.Conv2D(chs,(sh,sh),padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def create_cnn(SHAPE,channel):\n",
    "    input = Input(shape=(SHAPE,SHAPE,channel))\n",
    "    x = basic_conv_block(input, 64, 5, 1)\n",
    "    x = layers.AveragePooling2D(2)(x)\n",
    "    x = basic_conv_block(x, 128, 3, 3)\n",
    "    x = layers.AveragePooling2D(2)(x)\n",
    "    x = basic_conv_block(x, 256, 3, 3)\n",
    "    x = layers.GlobalAvgPool2D()(x)\n",
    "    x = layers.Dense(10)(x)\n",
    "    x = layers.Activation('softmax')(x)\n",
    "\n",
    "    model = Model(input, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import History, Callback\n",
    "from keras.objectives import categorical_crossentropy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "from scipy.stats import mode\n",
    "import os, pickle\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# 確率の平均を取るアンサンブル（ソフトアンサンブル）\n",
    "def ensembling_soft(models, X):\n",
    "    preds_sum = None\n",
    "    for model in models:\n",
    "        if preds_sum is None:\n",
    "            preds_sum = model.predict(X)\n",
    "        else:\n",
    "            preds_sum += model.predict(X)\n",
    "    probs = preds_sum / len(models)\n",
    "    return to_categorical(np.argmax(probs, axis=1), num_classes=10)\n",
    "\n",
    "# 多数決のアンサンブル（ハードアンサンブル）\n",
    "def ensembling_hard(models, X):\n",
    "    pred_labels = np.zeros((X.shape[0], len(models)))\n",
    "    for i, model in enumerate(models):\n",
    "        pred_labels[:, i] = np.argmax(model.predict(X), axis=1)\n",
    "    return to_categorical(mode(pred_labels, axis=1)[0], num_classes=10)\n",
    "\n",
    "class Checkpoint(Callback):\n",
    "    def __init__(self, model, filepath):\n",
    "        self.model = model\n",
    "        self.filepath = filepath\n",
    "        self.best_val_acc = 0.0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if self.best_val_acc < logs[\"val_acc\"]:\n",
    "            self.model.save_weights(self.filepath, save_format=\"h5\")\n",
    "            self.best_val_acc = logs[\"val_acc\"]\n",
    "            print(\"Weights saved.\", self.best_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 4 0 best val score 0.7360800000000001\n",
      "version: 4 1 best val score 0.74088\n",
      "version: 4 2 best val score 0.7392\n",
      "version: 4 3 best val score 0.74592\n",
      "(0.79008, 0.78128)\n"
     ]
    }
   ],
   "source": [
    "vers = 4\n",
    "\n",
    "def load_allmodels(vers,num,SHAPE,channel):\n",
    "    allmodels = []\n",
    "    for i in range(num):\n",
    "        train_model = create_cnn(SHAPE,channel)\n",
    "        train_model.load_weights(f\"weights{vers}_{i}.hdf5\")\n",
    "        for layer in train_model.layers:\n",
    "            layer.trainable = False\n",
    "        allmodels.append(train_model)\n",
    "    return allmodels\n",
    "\n",
    "def ensembling_both(models, X, y):\n",
    "    #soft ensemble\n",
    "    preds_sum = None\n",
    "    for model in models:\n",
    "        if preds_sum is None:\n",
    "            preds_sum = model.predict(X)\n",
    "        else:\n",
    "            preds_sum += model.predict(X)\n",
    "    probs = preds_sum / len(models)\n",
    "    soft_ens_y_pred = to_categorical(np.argmax(probs, axis=1), num_classes=10)\n",
    "    soft_ens_acc = accuracy_score(y, soft_ens_y_pred)\n",
    "    #hard ensemble\n",
    "    pred_labels = np.zeros((X.shape[0], len(models)))\n",
    "    for i, model in enumerate(models):\n",
    "        pred_labels[:, i] = np.argmax(model.predict(X), axis=1)\n",
    "    hard_ens_y_pred = to_categorical(mode(pred_labels, axis=1)[0], num_classes=10)\n",
    "    hard_ens_acc = accuracy_score(y, hard_ens_y_pred)\n",
    "    return soft_ens_acc, hard_ens_acc\n",
    "\n",
    "SHAPE=32\n",
    "channel=3\n",
    "allmodels = load_allmodels(vers,4,SHAPE,channel)\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    log_data = pd.read_csv('cf10_trlog_{}_{}'.format(vers,i), sep=',', engine='python')\n",
    "    print('version:',vers,i,'best val score',np.max(log_data.val_acc))\n",
    "#print('version:',vers,'soft ensemble val accuracy:',ensemble_tests_acc)\n",
    "#print('version:',vers,'hard ensemble val accuracy:',ensemble_test_acc_h)\n",
    "\n",
    "print(ensembling_both(allmodels,x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_8 (Average (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_9 (Average (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,856,650\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,856,650\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "allmodels[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_8 (Average (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_9 (Average (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,856,650\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,856,650\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#functional APIで作成したモデルの最終レイヤーを取り除く\n",
    "\n",
    "def funcmodelpop(model):\n",
    "    seq_model = Sequential()\n",
    "    for layer in model.layers[:-1]: # just exclude last layer from copying\n",
    "        seq_model.add(layer)\n",
    "    for layer in seq_model.layers:\n",
    "        layer.trainable = False\n",
    "    return seq_model\n",
    "\n",
    "teachers = []\n",
    "for i in range(len(allmodels)):\n",
    "    teachers.append(funcmodelpop(allmodels[i]))\n",
    "teachers[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_32 (Averag (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_33 (Averag (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_16  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,117,450\n",
      "Trainable params: 1,115,786\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_st(SHAPE,channel):\n",
    "    input = Input(shape=(SHAPE,SHAPE,channel))\n",
    "    x = basic_conv_block(input, 64, 5, 1)\n",
    "    x = layers.AveragePooling2D(2)(x)\n",
    "    x = basic_conv_block(x, 128, 3, 2)  ##repsを3から2に\n",
    "    x = layers.AveragePooling2D(2)(x)\n",
    "    x = basic_conv_block(x, 256, 3, 2)  ##repsを3から2に\n",
    "    x = layers.GlobalAvgPool2D()(x)\n",
    "    x = layers.Dense(10)(x)\n",
    "\n",
    "    model = Model(input, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "vers = 4\n",
    "\n",
    "student = create_cnn_st(SHAPE,channel)\n",
    "student.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_35 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_32 (Model)                (None, 10)           1117450     input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 10)           1856650     input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 10)           1856650     input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 10)           1856650     input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 10)           1856650     input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "student_softmax (Activation)    (None, 10)           0           model_32[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 50)           0           model_32[1][0]                   \n",
      "                                                                 sequential[9][0]                 \n",
      "                                                                 sequential_1[9][0]               \n",
      "                                                                 sequential_2[9][0]               \n",
      "                                                                 sequential_3[7][0]               \n",
      "==================================================================================================\n",
      "Total params: 8,544,050\n",
      "Trainable params: 1,115,786\n",
      "Non-trainable params: 7,428,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#合体させてく\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "\n",
    "model_input = Input(shape=(32,32,3))\n",
    "\n",
    "student_logid = student(model_input)\n",
    "teacher_logid_1 = teachers[0](model_input)\n",
    "teacher_logid_2 = teachers[1](model_input)\n",
    "teacher_logid_3 = teachers[2](model_input)\n",
    "teacher_logid_4 = teachers[3](model_input)\n",
    "#teacher_logid_5 = teachers[4](model_input)\n",
    "\n",
    "student_softmax = layers.Activation('softmax',name=\"student_softmax\")(student_logid)\n",
    "\n",
    "#teacher_ensemble = Concatenate(axis=-1)([teacher_logid_1, teacher_logid_2, teacher_logid_3, teacher_logid_4, teacher_logid_5])\n",
    "#teacher_logids = layers.Dense(10)(teacher_ensemble)\n",
    "\n",
    "logids = Concatenate(axis=-1)([student_logid,\n",
    "                               teacher_logid_1,\n",
    "                               teacher_logid_2,\n",
    "                               teacher_logid_3,\n",
    "                               teacher_logid_4,\n",
    "                               #teacher_logid_5\n",
    "                              ])\n",
    "\n",
    "model = Model(inputs=model_input, outputs=[student_softmax, logids])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainable paraがstudentのparameter、nonがteacherのparameter\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "temperature = 20.\n",
    "\n",
    "def distillation_loss(y_true, y_pred):\n",
    "    student_logid, teacher_logid_1, teacher_logid_2, teacher_logid_3, teacher_logid_4 = tf.split(y_pred, 5, axis=-1) #, teacher_logid_5\n",
    "  \n",
    "    student_soft = K.softmax(student_logid/temperature)\n",
    "    teacher_soft_1 = K.softmax(teacher_logid_1/temperature)\n",
    "    #teacher_soft_2 = K.softmax(teacher_logid_2/temperature)\n",
    "    #teacher_soft_3 = K.softmax(teacher_logid_3/temperature)\n",
    "    #teacher_soft_4 = K.softmax(teacher_logid_4/temperature)\n",
    "    #teacher_soft_5 = K.softmax(teacher_logid_5/temperature)\n",
    "    \n",
    "    preds_sum = teacher_soft_1\n",
    "    #preds_sum += teacher_soft_2\n",
    "    #preds_sum += teacher_soft_3\n",
    "    #preds_sum += teacher_soft_4\n",
    "    #preds_sum += teacher_soft_5\n",
    "    teacher_ensemble = preds_sum / 1\n",
    "\n",
    "    #teacher_ensemble = to_categorical(tf.math.argmax(probs, axis=1), num_classes=10)\n",
    "\n",
    "    \n",
    "    return K.categorical_crossentropy(teacher_ensemble, student_soft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37500 samples\n",
      "Epoch 1/50\n",
      "37500/37500 [==============================] - 23s 617us/sample - loss: 826.7808 - student_softmax_loss: 1.5607 - concatenate_8_loss: 2.2962\n",
      "Epoch 2/50\n",
      "37500/37500 [==============================] - 21s 552us/sample - loss: 825.5352 - student_softmax_loss: 1.0349 - concatenate_8_loss: 2.2929\n",
      "Epoch 3/50\n",
      "37500/37500 [==============================] - 21s 551us/sample - loss: 825.1411 - student_softmax_loss: 0.8132 - concatenate_8_loss: 2.2918\n",
      "Epoch 4/50\n",
      "37500/37500 [==============================] - 21s 551us/sample - loss: 824.9469 - student_softmax_loss: 0.6906 - concatenate_8_loss: 2.2913\n",
      "Epoch 5/50\n",
      "37500/37500 [==============================] - 21s 551us/sample - loss: 824.8182 - student_softmax_loss: 0.6041 - concatenate_8_loss: 2.2910\n",
      "Epoch 6/50\n",
      "37500/37500 [==============================] - 21s 551us/sample - loss: 824.7122 - student_softmax_loss: 0.5317 - concatenate_8_loss: 2.2907\n",
      "Epoch 7/50\n",
      "37500/37500 [==============================] - 21s 554us/sample - loss: 824.6384 - student_softmax_loss: 0.4786 - concatenate_8_loss: 2.2905\n",
      "Epoch 8/50\n",
      "37500/37500 [==============================] - 21s 552us/sample - loss: 824.5677 - student_softmax_loss: 0.4290 - concatenate_8_loss: 2.2903\n",
      "Epoch 9/50\n",
      "37500/37500 [==============================] - 21s 552us/sample - loss: 824.5064 - student_softmax_loss: 0.3898 - concatenate_8_loss: 2.2902\n",
      "Epoch 10/50\n",
      "37500/37500 [==============================] - 21s 549us/sample - loss: 824.4484 - student_softmax_loss: 0.3530 - concatenate_8_loss: 2.2900\n",
      "Epoch 11/50\n",
      "37500/37500 [==============================] - 21s 548us/sample - loss: 824.3957 - student_softmax_loss: 0.3190 - concatenate_8_loss: 2.2899\n",
      "Epoch 12/50\n",
      "37500/37500 [==============================] - 21s 554us/sample - loss: 824.3556 - student_softmax_loss: 0.2911 - concatenate_8_loss: 2.2898\n",
      "Epoch 13/50\n",
      "37500/37500 [==============================] - 21s 552us/sample - loss: 824.3125 - student_softmax_loss: 0.2642 - concatenate_8_loss: 2.2897\n",
      "Epoch 14/50\n",
      "37500/37500 [==============================] - 21s 549us/sample - loss: 824.2760 - student_softmax_loss: 0.2372 - concatenate_8_loss: 2.2896\n",
      "Epoch 15/50\n",
      "37500/37500 [==============================] - 21s 548us/sample - loss: 824.2418 - student_softmax_loss: 0.2197 - concatenate_8_loss: 2.2895\n",
      "Epoch 16/50\n",
      "37500/37500 [==============================] - 21s 548us/sample - loss: 824.2106 - student_softmax_loss: 0.2001 - concatenate_8_loss: 2.2894\n",
      "Epoch 17/50\n",
      "37500/37500 [==============================] - 21s 552us/sample - loss: 824.1843 - student_softmax_loss: 0.1853 - concatenate_8_loss: 2.2893\n",
      "Epoch 18/50\n",
      "37500/37500 [==============================] - 21s 550us/sample - loss: 824.1583 - student_softmax_loss: 0.1716 - concatenate_8_loss: 2.2893\n",
      "Epoch 19/50\n",
      "37500/37500 [==============================] - 21s 552us/sample - loss: 824.1293 - student_softmax_loss: 0.1560 - concatenate_8_loss: 2.2892\n",
      "Epoch 20/50\n",
      "37500/37500 [==============================] - 21s 553us/sample - loss: 824.1097 - student_softmax_loss: 0.1482 - concatenate_8_loss: 2.2892\n",
      "Epoch 21/50\n",
      "37500/37500 [==============================] - 21s 549us/sample - loss: 824.0886 - student_softmax_loss: 0.1388 - concatenate_8_loss: 2.2891\n",
      "Epoch 22/50\n",
      "37500/37500 [==============================] - 21s 550us/sample - loss: 824.0705 - student_softmax_loss: 0.1297 - concatenate_8_loss: 2.2891\n",
      "Epoch 23/50\n",
      "37500/37500 [==============================] - 21s 552us/sample - loss: 824.0511 - student_softmax_loss: 0.1224 - concatenate_8_loss: 2.2890\n",
      "Epoch 24/50\n",
      "37500/37500 [==============================] - 21s 552us/sample - loss: 824.0328 - student_softmax_loss: 0.1142 - concatenate_8_loss: 2.2889\n",
      "Epoch 25/50\n",
      "37500/37500 [==============================] - 21s 550us/sample - loss: 824.0204 - student_softmax_loss: 0.1108 - concatenate_8_loss: 2.2889\n",
      "Epoch 26/50\n",
      "37500/37500 [==============================] - 21s 553us/sample - loss: 824.0114 - student_softmax_loss: 0.1074 - concatenate_8_loss: 2.2889\n",
      "Epoch 27/50\n",
      "37500/37500 [==============================] - 21s 549us/sample - loss: 823.9912 - student_softmax_loss: 0.1010 - concatenate_8_loss: 2.2888\n",
      "Epoch 28/50\n",
      "37500/37500 [==============================] - 21s 552us/sample - loss: 823.9794 - student_softmax_loss: 0.0971 - concatenate_8_loss: 2.2888\n",
      "Epoch 29/50\n",
      "37500/37500 [==============================] - 21s 551us/sample - loss: 823.9717 - student_softmax_loss: 0.0952 - concatenate_8_loss: 2.2888\n",
      "Epoch 30/50\n",
      "37500/37500 [==============================] - 21s 551us/sample - loss: 823.9588 - student_softmax_loss: 0.0900 - concatenate_8_loss: 2.2888\n",
      "Epoch 31/50\n",
      "37500/37500 [==============================] - 21s 553us/sample - loss: 823.9520 - student_softmax_loss: 0.0892 - concatenate_8_loss: 2.2887\n",
      "Epoch 32/50\n",
      "37500/37500 [==============================] - 21s 552us/sample - loss: 823.9436 - student_softmax_loss: 0.0867 - concatenate_8_loss: 2.2887\n",
      "Epoch 33/50\n",
      "37500/37500 [==============================] - 21s 551us/sample - loss: 823.9346 - student_softmax_loss: 0.0842 - concatenate_8_loss: 2.2887\n",
      "Epoch 34/50\n",
      "37500/37500 [==============================] - 21s 553us/sample - loss: 823.9287 - student_softmax_loss: 0.0834 - concatenate_8_loss: 2.2887\n",
      "Epoch 35/50\n",
      "37500/37500 [==============================] - 21s 549us/sample - loss: 823.9178 - student_softmax_loss: 0.0810 - concatenate_8_loss: 2.2886\n",
      "Epoch 36/50\n",
      "37500/37500 [==============================] - 21s 551us/sample - loss: 823.9134 - student_softmax_loss: 0.0797 - concatenate_8_loss: 2.2886\n",
      "Epoch 37/50\n",
      "37500/37500 [==============================] - 21s 551us/sample - loss: 823.9055 - student_softmax_loss: 0.0779 - concatenate_8_loss: 2.2886\n",
      "Epoch 38/50\n",
      "37500/37500 [==============================] - 21s 551us/sample - loss: 823.9002 - student_softmax_loss: 0.0766 - concatenate_8_loss: 2.2886\n",
      "Epoch 39/50\n",
      "37500/37500 [==============================] - 21s 552us/sample - loss: 823.8923 - student_softmax_loss: 0.0744 - concatenate_8_loss: 2.2886\n",
      "Epoch 40/50\n",
      "37500/37500 [==============================] - 21s 551us/sample - loss: 823.8854 - student_softmax_loss: 0.0725 - concatenate_8_loss: 2.2885\n",
      "Epoch 41/50\n",
      "37500/37500 [==============================] - 21s 549us/sample - loss: 823.8822 - student_softmax_loss: 0.0722 - concatenate_8_loss: 2.2885\n",
      "Epoch 42/50\n",
      "37500/37500 [==============================] - 21s 551us/sample - loss: 823.8797 - student_softmax_loss: 0.0723 - concatenate_8_loss: 2.2885\n",
      "Epoch 43/50\n",
      "37500/37500 [==============================] - 21s 553us/sample - loss: 823.8711 - student_softmax_loss: 0.0697 - concatenate_8_loss: 2.2885\n",
      "Epoch 44/50\n",
      "37500/37500 [==============================] - 21s 553us/sample - loss: 823.8700 - student_softmax_loss: 0.0699 - concatenate_8_loss: 2.2885\n",
      "Epoch 45/50\n",
      "37500/37500 [==============================] - 21s 551us/sample - loss: 823.8657 - student_softmax_loss: 0.0688 - concatenate_8_loss: 2.2885\n",
      "Epoch 46/50\n",
      "37500/37500 [==============================] - 21s 553us/sample - loss: 823.8621 - student_softmax_loss: 0.0683 - concatenate_8_loss: 2.2885\n",
      "Epoch 47/50\n",
      "37500/37500 [==============================] - 21s 551us/sample - loss: 823.8557 - student_softmax_loss: 0.0673 - concatenate_8_loss: 2.2885\n",
      "Epoch 48/50\n",
      "37500/37500 [==============================] - 21s 551us/sample - loss: 823.8534 - student_softmax_loss: 0.0670 - concatenate_8_loss: 2.2885\n",
      "Epoch 49/50\n",
      "37500/37500 [==============================] - 21s 551us/sample - loss: 823.8493 - student_softmax_loss: 0.0652 - concatenate_8_loss: 2.2885\n",
      "Epoch 50/50\n",
      "37500/37500 [==============================] - 20s 545us/sample - loss: 823.8460 - student_softmax_loss: 0.0651 - concatenate_8_loss: 2.2884\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "lambda_const = 0.9\n",
    "adam = optimizers.Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "model.compile(loss = [\"categorical_crossentropy\",distillation_loss], loss_weights=[1-lambda_const, lambda_const * temperature**2], optimizer = adam)\n",
    "\n",
    "\n",
    "#student learning with teacher modelsff\n",
    "\n",
    "EPOCHS = 50\n",
    "csv_logger = CSVLogger('distill_trlog_student_{}'.format(vers), separator=',', append=False)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_acc\", patience=8)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-5)\n",
    "learning_rate = LearningRateScheduler(step_decay,verbose=1)\n",
    "#cp = Checkpoint_student(model, student, f\"weights_student{vers}.hdf5\")\n",
    "\n",
    "history = model.fit(x=x_train,\n",
    "                    y=[y_train,y_train],\n",
    "                    epochs=EPOCHS,\n",
    "                    #validation_data=(x_val,y_val),\n",
    "                    #validation_steps=50,\n",
    "                    #use_multiprocessing=True,\n",
    "                    #workers=4,\n",
    "                    callbacks=[#cp,\n",
    "                               #early_stopping,\n",
    "                               csv_logger]\n",
    "                               #learning_rate]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 2s 143us/sample - loss: 0.6445 - accuracy: 0.7918\n",
      "[0.6445278978729249, 0.79184]\n",
      "version: 4 0 best val score 0.7360800000000001\n",
      "(0.73608, 0.73608)\n"
     ]
    }
   ],
   "source": [
    "#1model\n",
    "full_input = Input(shape=(32,32,3))\n",
    "full_logid = student(full_input)\n",
    "full_output = layers.Activation('softmax')(full_logid)\n",
    "\n",
    "full_student = Model(inputs=full_input, outputs=full_output)\n",
    "\n",
    "full_student.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics = [\"accuracy\"])\n",
    "#full_student.summary()\n",
    "\n",
    "print(full_student.evaluate(x_val, y_val))\n",
    "\n",
    "for i in range(1):\n",
    "    log_data = pd.read_csv('cf10_trlog_{}_{}'.format(vers,i), sep=',', engine='python')\n",
    "    print('version:',vers,i,'best val score',np.max(log_data.val_acc))\n",
    "#print('version:',vers,'soft ensemble val accuracy:',ensemble_tests_acc)\n",
    "#print('version:',vers,'hard ensemble val accuracy:',ensemble_test_acc_h)\n",
    "\n",
    "print(ensembling_both(allmodels[:1],x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 2s 153us/sample - loss: 0.5760 - accuracy: 0.8080\n",
      "[0.5759807893753052, 0.808]\n",
      "version: 4 0 best val score 0.7360800000000001\n",
      "version: 4 1 best val score 0.74088\n",
      "(0.73608, 0.73608)\n"
     ]
    }
   ],
   "source": [
    "#2model\n",
    "full_input = Input(shape=(32,32,3))\n",
    "full_logid = student(full_input)\n",
    "full_output = layers.Activation('softmax')(full_logid)\n",
    "\n",
    "full_student = Model(inputs=full_input, outputs=full_output)\n",
    "\n",
    "full_student.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics = [\"accuracy\"])\n",
    "#full_student.summary()\n",
    "\n",
    "print(full_student.evaluate(x_val, y_val))\n",
    "\n",
    "for i in range(2):\n",
    "    log_data = pd.read_csv('cf10_trlog_{}_{}'.format(vers,i), sep=',', engine='python')\n",
    "    print('version:',vers,i,'best val score',np.max(log_data.val_acc))\n",
    "#print('version:',vers,'soft ensemble val accuracy:',ensemble_tests_acc)\n",
    "#print('version:',vers,'hard ensemble val accuracy:',ensemble_test_acc_h)\n",
    "\n",
    "print(ensembling_both(allmodels[:1],x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "model_25 (Model)             (None, 10)                1117450   \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,117,450\n",
      "Trainable params: 1,115,786\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "12500/12500 [==============================] - 2s 148us/sample - loss: 0.5574 - accuracy: 0.8140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5574472402954102, 0.814]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3model\n",
    "full_input = Input(shape=(32,32,3))\n",
    "full_logid = student(full_input)\n",
    "full_output = layers.Activation('softmax')(full_logid)\n",
    "\n",
    "full_student = Model(inputs=full_input, outputs=full_output)\n",
    "\n",
    "full_student.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics = [\"accuracy\"])\n",
    "full_student.summary()\n",
    "\n",
    "full_student.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 4 0 best val score 0.7360800000000001\n",
      "version: 4 1 best val score 0.74088\n",
      "version: 4 2 best val score 0.7392\n",
      "(0.76688, 0.73952)\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    log_data = pd.read_csv('cf10_trlog_{}_{}'.format(vers,i), sep=',', engine='python')\n",
    "    print('version:',vers,i,'best val score',np.max(log_data.val_acc))\n",
    "#print('version:',vers,'soft ensemble val accuracy:',ensemble_tests_acc)\n",
    "#print('version:',vers,'hard ensemble val accuracy:',ensemble_test_acc_h)\n",
    "\n",
    "print(ensembling_both(allmodels[:2],x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "model_18 (Model)             (None, 10)                1117450   \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,117,450\n",
      "Trainable params: 1,115,786\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "12500/12500 [==============================] - 2s 148us/sample - loss: 0.5505 - accuracy: 0.8194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5505422951507568, 0.81936]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4model\n",
    "full_input = Input(shape=(32,32,3))\n",
    "full_logid = student(full_input)\n",
    "full_output = layers.Activation('softmax')(full_logid)\n",
    "\n",
    "full_student = Model(inputs=full_input, outputs=full_output)\n",
    "\n",
    "full_student.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics = [\"accuracy\"])\n",
    "full_student.summary()\n",
    "\n",
    "full_student.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 4 0 best val score 0.7360800000000001\n",
      "version: 4 1 best val score 0.74088\n",
      "version: 4 2 best val score 0.7392\n",
      "version: 4 3 best val score 0.74592\n",
      "(0.77984, 0.77152)\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    log_data = pd.read_csv('cf10_trlog_{}_{}'.format(vers,i), sep=',', engine='python')\n",
    "    print('version:',vers,i,'best val score',np.max(log_data.val_acc))\n",
    "#print('version:',vers,'soft ensemble val accuracy:',ensemble_tests_acc)\n",
    "#print('version:',vers,'hard ensemble val accuracy:',ensemble_test_acc_h)\n",
    "\n",
    "print(ensembling_both(allmodels[:3],x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
